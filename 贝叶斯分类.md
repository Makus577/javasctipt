### 贝叶斯分类

算法的基础：贝叶斯定理

栗子： 朴素贝叶斯分类



从数学角度来说，分类定义：

> 以及集合：C= {y1, y2, ….., yn} 和 I= {x1, x2, ….xm, ….}，确认映射规则y=f(x),使得任意xi 属于 I 有且仅有一个 yi 属于C 使得 y = f(x) 成立。
>
> 其中C叫做类别集合，其中每一个元素是一个类别，而I叫做项集合，其中每一个元素是一个待分类项，f叫做分类器。分类算法的任务就是构建分类器f。

这里要着重强调，分类问题往往采用经验性方法构造映射规则，即一般情况下的分类问题缺少足够的信息来构造100%正确的映射规则，而是通过对经验数据的学习从而实现一定概率意义上正确的分类，因此所训练出的分类器并不是一定能将每个待分类项准确映射到其分类，分类器的质量与分类器构造方法、待分类数据的特性以及训练样本数量等诸多因素有关。



#### 贝叶斯定理

条件概率：P（A|B）表示事件B已经发生的前提下，事件A发生的概率，叫做事件B发生下事件A的条件概率。其基本求解公式为：P（A|B）= P（AB）／P（B）。

贝叶斯定理： P（B|A）= P（A|B）P（B）／P（A）



#### 朴素贝叶斯分类

对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，那个概率最大，就认为此待分类项属于哪个类别。

正式定义如下：

1. 设x={a1, a2, ….., am}为一个待分类项，而每个a为x的一个特征属性
2. 有类别记得C = {y1, y2, …, yn}
3. 计算P（y1|x）,P(y2|x),....P(yn|X)
4. 如果P（yk|x）= max(P（y1|x）,P(y2|x),....P(yn|X)),则x属于yk



#### 估计类别下特征属性划分的条件概率及Laplace校准

计算各个划分的条件概率P（a|y）是朴素贝叶斯分类的关键性步骤，当步骤属性为离散值时，只是很方便的统计训练样本中各个划分在每个类别中出现的频率即可用来估计P（a|y）,下面重点讨论特征属性时连续值的情况。

当特征属性是连续值时，通常假定其值服从高斯分布（也称正态分布）。即：

 。。。。。

另一个需要讨论的问题就是当P（a|y）=0怎么办，当某个类别下某个特征项划分没有出现时，就会产生这种现象，这会令分类器质量大大降低。为了解决这个问题，我们引入Laplace校准，就是对每个类别下所有划分的计数+1，这样如果训练样本集数量充分大时，并不会对结果产生影响，并且解决了上述频率为0的尴尬局面





















